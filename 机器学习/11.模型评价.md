# 模型评价

## 交叉验证

- k-折交叉验证

在scikit-learn中默认使用的交叉验证法是*K*折叠交叉验证法（k-fold cross validation）。这种方法很容易理解——它将数据集拆分成*k*个部分，再用*k*个数据集对模型进行训练和评分。例如我们令*k*等于5，则数据集被拆分成5个，其中第1个子集会被作为测试数据集，另外4个用来训练模型。之后再用第2个子集作为测试集，而另外4个用来训练模型。依此类推，直到把5个数据集全部用完，这样我们就会得到5个模型的评分

```python
from sklearn.datasets import load_wine
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC

wine = load_wine()
X = wine.data
y = wine.target

svc = SVC(kernel="linear")
svc.fit(X, y)
cross_val_score(svc, X, y, verbose=0, cv=6)# 取均值即可
```

![image-20240702162703538](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702162703538.png)

- 随机拆分交叉验证

从数据集中随机抽一部分数据集作为训练集，再从其余的部分随机抽一部分作为测试集，进行评分后再迭代，重复上一步的动作，直到把我们希望迭代的次数全部跑完, 和上面的不一样，这个是每次抽取70%训练数据，20%的测试数据迭代十次；上面的是比如cv=10，会把数据拆成10份，每一份分别做测试集，剩下的数据做训练集，进行迭代

```python
from sklearn.model_selection import cross_val_score,ShuffleSplit
shuff_split = ShuffleSplit(test_size=0.2, train_size=0.7, n_splits = 10)
cross_val_score(svc, X, y, verbose=2, cv=shuff_split)
```

![image-20240702163038875](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702163038875.png)

- 逐一测试

将数据集中每一个点作为测试集，剩下的数作为训练集进行评分，这个最准，但是及其耗费时间

```python
from sklearn.model_selection import LeaveOneOut
cv = LeaveOneOut()
cross_val_score(svc, X, y, verbose=1, cv=cv).mean()
# 10s 慢100倍了...
```

![image-20240702164355246](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702164355246.png)

当我们使用train_test_split方法进行数据集的拆分时，train_test_splt用的是随机拆分的方法，万一我们拆分的时候，测试集中都是比较容易进行分类或者回归的数据，而训练集中都比较难，那么模型的得分就会偏高，反之模型的得分就会偏低。我们又不太可能把所有的random_state遍历一遍。而交叉验证法正好弥补了这个缺陷，它的工作原理导致它要对多次拆分进行评分再取平均值，这样就不会出现我们前面所说的问题。

此外，train_test_split总是按照25%～75%的比例来拆分训练集与测试集（默认情况下），但当我们使用交叉验证法的时候，可以更加灵活地指定训练集和测试集的大小，比如当cv参数为10的时候，训练集就会占整个数据集的90%，测试集占10%；cv参数为20的时候，训练集的占比就会达到95%，而测试集占比5%。这也意味着训练集会更大，对于模型的准确率也有促进的作用。

## GridSearchCV参数调节

有的模型的参数多，如果想要确定最佳参数，一个方法就是每个参数都给定一个list，然后开始for循环套娃迭代构建模型+交叉验证然后得到最优参数组合，GridSearchCV封装优化了这个过程，用起来很方便

```python
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.datasets import load_wine
wine = load_wine()
X = wine.data
y = wine.target

X_train, X_test, y_train, y_test = train_test_split(X, y)
lasso = Lasso()
lasso.fit(X_train, y_train)
params = {
    'alpha':[0.01, 0.1, 1, 10],
    'max_iter':[100, 200, 1000, 5000, 10000]
}
grid_search = GridSearchCV(lasso, param_grid=params, cv = 6)
grid_search.fit(X_train, y_train)
grid_search.score(X_test, y_test)
```

查看最佳参数和交叉验证的最佳得分

![image-20240702170653797](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702170653797.png)

## 分类模型的评价

在scikit-learn中，很多用于分类的模型都有一个predict_proba功能，这个功能就是用于计算模型在对数据集进行分类时，每个样本属于不同分类的可能性是多少

构建一个三分类的数据

- **predict_proba**

```python
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
X, y = make_blobs(n_samples=1000, random_state=1, centers=3, cluster_std=5)
X_train, X_test, y_train, y_test = train_test_split(X, y)
plt.scatter(X[:,0],X[:,1], c=y)
```

![image-20240702172148006](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702172148006.png)

```python
gnb = GaussianNB()
gnb.fit(X_train, y_train)
gnb.predict(X_test)[0:5]
gnb.predict_proba(X_test)[0:5]
```

![image-20240702172249293](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702172249293.png)

分别会得到每个样本属于每个分类的概率，概率最高的即为目标分类

- **decision_function**

  在机器学习中，特别是在分类算法如支持向量机（SVM）中，`decision_function` 是一个非常重要的概念。以下是对 `decision_function` 的理解：

  1. **定义**： `decision_function` 是一个函数，它对每个样本计算一个值，这个值表示样本与决策边界的关系。在二分类问题中，这个值可以是正数或负数，用以指示样本属于正类还是负类。
  2. **工作原理**：
     - 对于线性分类器，`decision_function` 通常计算样本特征向量与权重向量的点积，再加上偏置项（bias）。
     - 对于非线性分类器，如使用核技巧的SVM，`decision_function` 会计算核函数在样本特征上的值，然后应用权重和偏置项。
  3. **值的解释**：
     - **正数**：如果 `decision_function` 的值是正数，样本通常被预测为正类。
     - **负数**：如果值是负数，样本通常被预测为负类。
     - **零**：如果值接近零，样本可能位于决策边界附近。
  4. **距离度量**：
     - 在线性模型中，`decision_function` 的值实际上表示样本到决策边界的距离。正值表示样本位于决策边界的正侧，负值表示位于负侧。
  5. **置信度**：
     - `decision_function` 的绝对值大小可以提供关于分类决策的信心水平。值的绝对值越大，分类结果的置信度越高。
  6. **多类问题**：
     - 在多类分类问题中，`decision_function` 可能需要为每个类别计算一个得分，然后选择得分最高的类别作为预测结果。

```python
from sklearn.svm import SVC
#使用训练集训练模型
svc = SVC(probability=False).fit(X_train, y_train)
#获得SVC的决定系数
dec_func = svc.decision_function(X_test)

svc.predict(X_test)[0:5]
dec_func[0:5]
```

![image-20240702172534203](https://51catgithubio.oss-cn-beijing.aliyuncs.com/image-20240702172534203.png)

## 混淆矩阵



## 精度（Precision）



## 召回率（Recall）

The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of
true positives and ``fn`` the number of false negatives. The recall is
intuitively the ability of the classifier to find all the positive samples.

The best value is 1 and the worst value is 0.

- *TP* 是真正例的数量（即模型正确预测为正类的样本数）。
- *FN* 是假负例的数量（即模型错误预测为负类的正类样本数）。

```python
# 二分类
from sklearn.metrics import recall_score

# 真实标签
y_true = [0, 1, 0, 1]
# 模型预测的标签
y_pred = [0, 1, 1, 0]

# 计算召回率
recall = recall_score(y_true, y_pred)

print(f'Recall: {recall}') #Recall: 0.5
```

多分类任务

```python
from sklearn.metrics import recall_score
# 多标签分类问题的真实标签和预测
y_true_multilabel = [[1, 0, 1], [0, 1, 0], [1, 1, 0]]
y_pred_multilabel = [[0, 0, 1], [1, 1, 0], [0, 1, 1]]

# 计算多标签分类问题的召回率
recall_multilabel = recall_score(y_true_multilabel, y_pred_multilabel, average='macro')

print(f'Multilabel Recall: {recall_multilabel}') #Recall: 0.66666
```

关于average的选择KIMI

```
这些参数描述的是scikit-learn中用于评估分类模型性能的不同方法，特别是在多类分类问题中。以下是对每个参数的解释：

'binary'：
仅报告由pos_label指定的类的评估结果。这仅适用于目标（y_true和y_pred）是二元的情况。

'micro'：
全局计算指标，通过计算所有类别的总真正例、假负例和假正例来得出。这种方式不考虑每个类别的特定情况，而是把所有类别合并在一起计算。

'macro'：
对每个标签分别计算指标，然后计算它们的未加权平均值。这种方式不会考虑标签的不平衡问题。

'weighted'：
对每个标签分别计算指标，然后根据每个标签的支持度（即每个标签的真实实例数量）进行加权平均。这种方式与'macro'不同，它考虑了标签不平衡的问题。加权召回率等同于准确率。

'samples'：
对每个实例分别计算指标，然后计算它们的平均值。这在多标签分类中是有意义的，因为它与accuracy_score函数计算的准确率不同。

在多类分类问题中，选择哪种方法取决于你的具体需求和数据集的特性。例如：

如果你想要对每个类别的预测性能进行平均考虑，不考虑类别的不平衡性，可以选择'macro'。
如果你想要考虑到类别的不平衡性，可以选择'weighted'。
如果你只关心特定类别的预测性能，可以选择'binary'。
如果你想要得到一个总体的评估指标，可以选择'micro'。
如果你想要对每个样本的预测性能进行平均考虑，可以选择'samples'。
```



## f1分数（f1-score）



## ROC（Receiver Operating Characteristic Curve）



## AUC（Area Under Curve）



## 使用SHAP包评价模型
